%

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{bbold}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{Linear Algebra with Application\\
to Engineering Computation}
\chead{}
\rhead{CME 200/ME300A\\
M. Gerritsen\\
Fall 2013}
\headheight = 40pt



%th in the exponent (e.g. when writing ith, instead use i$\eth$)
\newcommand{\eth}{^{\text{th}}}


\newcommand{\R}{\mathbb{R}}

%short-cuts for Greek letters
\newcommand{\al}{\alpha}
\newcommand{\dlt}{\delta}
\newcommand{\eps}{\epsilon}

%times (cross-product)
\newcommand{\x}{\times}
%inverse
\newcommand{\inv}{^{-1}}
%cond
\newcommand{\cond}{\mathrm{cond}}
%trace
\newcommand{\trace}{\mathrm{trace}}

\newcommand{\twith}{\text{ with }}
\newcommand{\tand}{\text{ and }}
\newcommand{\tfor}{\text{ for }}
\newcommand{\tor}{\text{ or }}

\newcommand{\ip}{_{i+1}}
\newcommand{\im}{_{i-1}}

\newcommand{\half}{\frac{1}{2}}
\newcommand{\oneby}[1]{\frac{1}{#1}}
\newcommand{\overto}[1]{\overset{#1}{\longrightarrow}} 
 

\newcommand{\rowsp}{\mathrm{rowsp}} 
 
%matrices
\newcommand{\bmat}[1]{\begin{bmatrix}#1\end{bmatrix}} 
 

%parentheses
\newcommand{\paren}[1]{\left(#1\right)}
\newcommand{\brac}[1]{\left[#1\right]}
\newcommand{\cbrac}[1]{\left\{#1\right\}} 
 
 
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%       DOCUMENT STRUCTURE COMMANDS
%       Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}
\newcommand\overmat[2]{%
  \makebox[0pt][l]{$\smash{\overbrace{\phantom{%
    \begin{matrix}#2\end{matrix}}}^{\text{$#1$}}}$}#2}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\title{Midterm Solutions}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle
\thispagestyle{fancy}


% Problem 1
\begin{homeworkProblem} %(15)
%Problem 1
We are given the LU decomposition of a matrix $A$ as
\[ A = LU = 
   \bmat{1 & 0 & 0 & 0 \\
                 2 & 1 & 0 & 0 \\
                 2 & 1 & 1 & 0 \\
                 3 & 2 & 4 & 1 }
   \bmat{1 & 2 & 0 & 1 & 2 & 1 \\
                 0 & 0 & 2 & 2 & 0 & 0 \\
                 0 & 0 & 0 & 0 & 0 & 1 \\
                 0 & 0 & 0 & 0 & 0 & 0 }. \]

\begin{enumerate}[(a)]
\item What is the rank $r(A)$ of matrix $A$? Explain

\item Find a basis for the null space of $A$. Show your work.

\item Find a basis for the column space of $A$. Show your work

\item For $\vec b = \bmat{1 \\1\\1\\1}$ do solution(s) to $A\vec x = \vec b$ exist? Clearly motivate your answer. Note that it is not necessary to compute the solution(s).
\end{enumerate}


\problemAnswer{
\begin{enumerate}[(a)]

\item First, recall that $r(A) = \dim(R(A)) = \dim(\rowsp(A))$. Now, since we are already given the LU decomposition of $A$, we can tell the rank of matrix $A$ by counting the number of non-zero rows in $U$, which corresponds to the number of linearly independent rows in $A$, i.e. $\dim(\rowsp(A))$. There are 3 non-zero rows in $U$, hence $r(A) = 3$.

\item There are a couple of ways to get the basis for the null space of $A$. (The method presented here was not the only way to get full credit.)\\
We recall that for $A\in\R^{m \x n}$, the null space $N(A)$ is defined as, 
\[ N(A) = \{\vec x \in \R^n | A \vec x =\vec 0 \}. \]
We know that $N(U) \subseteq N(A)$ (since if $\vec x \in N(U)$, then  $U \vec x = \vec 0$ and $A \vec x = LU\vec x = L \vec 0 = \vec 0$, so $\vec x \in N(A)$). Since $L$ is a triangular matrix with non-zero entries on the diagonal, we know that it is non-singular, i.e. it has full rank. Hence, $N(A) \subseteq N(U)$ (for suppose $\vec x \in N(A)$ and $\vec x \not\in N(U)$, then $U\vec x = \vec y \ne \vec 0$ and we get a contradiction $A \vec x = L U \vec x = L \vec y \ne \vec 0$, since $L$ has full column rank).\\
Thus, we have $N(A) = N(U)$ and we can find a basis for the null space of $A$ by working with $U$ directly.
\end{enumerate}
}

\problemAnswer{
Suppose, $\vec x \in N(U)$, $\vec x = \bmat{x_1 & x_2 & x_3 & x_4 & x_5 & x_6}^T$. Then,
\[ U\vec x = \bmat{1 & 2 & 0 & 1 & 2 & 1 \\
                                   0 & 0 & 2 & 2 & 0 & 0 \\
                                   0 & 0 & 0 & 0 & 0 & 1 \\
                                   0 & 0 & 0 & 0 & 0 & 0 }
                         \bmat{x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5 \\ x_6} = 
                         \bmat{0 \\ 0 \\ 0 \\ 0 }. \]
We get the following set of equations
\begin{align*}
x_1 + 2x_2 + x_4 + 2x_5 + x_6 &= 0 \implies x_1 = - 2x_2 - x_4 - 2x_5 - x_6, \\
2x_3 + 2x_4 &= 0 \implies x_3 = -x_4,\\
x_6 &= 0. 
\end{align*}
Choosing the free parameters, $x_2 = r,\ x_4 = s,\ x_5 = t$, we plug in to the equations above to get
\begin{align*}
x_1 &= - 2r - s - 2t \\
x_2 &= r\\
x_3 &= -s\\
x_4 &= s\\
x_5 &= t\\
x_6 &= 0. 
\end{align*}
Hence, every vector in the null space of $A$ can written as,
\[ \vec x = \bmat{- 2r - s - 2t \\ r\\ -s\\ s\\ t\\ 0} =
 r\bmat{- 2\\ 1\\ 0\\ 0\\ 0\\ 0} + s\bmat{-1\\ 0\\ -1\\ 1\\ 0\\ 0} + t\bmat{-2\\ 0\\ 0\\ 0\\ 1\\ 0} = r\vec a + s \vec b + t\vec c. \]


Since, $r,\ s,\tand t$ are free parameters, the entire null space of $A$ is comprised of linear combinations of the three vectors $\vec a,\ \vec b,\ \vec c$, i.e.
\[ N(A) = \cbrac{\bmat{- 2\\ 1\\ 0\\ 0\\ 0\\ 0}, \bmat{-1\\ 0\\ -1\\ 1\\ 0\\ 0}, \bmat{-2\\ 0\\ 0\\ 0\\ 1\\ 0} }. \]
[Note that depending on the choice of the free parameters, the resultant basis vectors could differ. However, we only need to make sure that the vectors are linearly independent and they indeed span the null space.]

You can easily, verify that the vectors $\vec a,\ \vec b,\ \vec c$ are in the null space of $U$ by multiplying each one of them by $U$. Also, by observation it is easy to see that these three vectors are linearly independent. Finally, the dimension of the null space is $\dim(N(A)) = n - r(A) = 6-3 = 3$ by the subtle theorem. Hence, we indeed found a basis for the null space of $A$.\\

\begin{enumerate}[(c)]
\item The idea here is to multiply $L$ and $U$ to get $A$, and then the columns of $A$ corresponding to the pivot
\end{enumerate}
}

\problemAnswer{ 
positions of $U$ will form the column space of $A$. Therefore
\begin{align*}
A = LU = 
\bmat{
 1  &   2  &   0   &  1  &   2  &   1\\
 2  &   4  &   2  &   4  &   4  &   2\\
 2  &   4  &   2  &   4  &   4  &   3\\
 3  &   6  &   4  &   7  &   6  &   7
}
\end{align*}
The column space can therefore be taken as columns $\{1, 3, 6\}$ or $\{1, 4, 6\}$ of $A$, and column 3 may be scaled by $\frac{1}{2}$. Your answer here affects the next part so this was taken into account. (Note - many students took the columns from $U$ and not $A$ and this is incorrect.)

\begin{enumerate}[(d)]
\item There are a few ways to do this. The easiest way is if you notice that
\begin{align*}
\vec{b} = 
\bmat{
 1\\1\\ 1\\ 1
} =
\bmat{
 1\\2\\ 2\\ 3
} -\frac{1}{2}\bmat{
 0\\2\\ 2\\ 4
}
\end{align*}
which means that it is indeed spanned by the columns of $A$. A more systematic way to arrive at this is by actually solving for the coefficients of the linear combinations of the columns in the column space of $A$ which will give $\vec{b}$
\begin{align*}
\alpha_1\bmat{
 1\\2\\ 2\\ 3
} + \alpha_2\bmat{
 0\\2\\ 2\\ 4
} + \alpha_3 \bmat{
 1\\2\\ 3\\ 7
} &= \bmat{
 1\\1\\ 1\\ 1
} \\
\end{align*}
There is no need to fully solve this system, only need to row reduce the augmented matrix and show that there is no inconsistent row.
\begin{align*}
\left(
\begin{array}{ccc|c}
1 & 0 & 1 & 1 \\ 
2 & 2 & 2 & 1 \\ 
2 & 2 & 3 & 1 \\ 
3 & 4 & 7 & 1 \\ 
    \end{array}
\right) \rightarrow
\left(
\begin{array}{ccc|c}
1 & 0 & 1 & 1 \\ 
0 & 2 & 0 & -1 \\ 
0 & 2 & 1 & -1 \\ 
0 & 4 & 4 & -2 \\ 
    \end{array}
\right) \rightarrow
\left(
\begin{array}{ccc|c}
1 & 0 & 1 & 1 \\ 
0 & 2 & 0 & -1 \\ 
0 & 0 & 1 & 0 \\ 
0 & 0 & 4 & 0 \\ 
    \end{array}
\right) \rightarrow
\left(
\begin{array}{ccc|c}
1 & 0 & 1 & 1 \\ 
0 & 2 & 0 & -1 \\ 
0 & 0 & 1 & 0 \\ 
0 & 0 & 0 & 0 \\ 
    \end{array}
\right)
\end{align*}
Yet another way to do this is by looking at 
\begin{align*}
Ax &=b \\
LUx &= b\\
Ly &= b\\
Ux &= y
\end{align*}
You can solve for $y$ by performing forward substitution or computing the inverse of $L$ and multiplying this to $b$. However many people made mistakes in computing the inverse of $L$ so this is a bad idea. You should get 
\begin{align*}
y = \bmat{1 \\ -1 \\ 0 \\ 0}
\end{align*}

\end{enumerate}
}
\problemAnswer{
At this point you can explicitly solve $Ux = y$  to get the solution or simply observe that wherever $U$ has all zero rows (in this case only the last row) $y$ also has zero component (the last two components). Therefore the system has at least one solution, in fact infinitely many solutions.
}
\end{homeworkProblem}

% Problem 2



\begin{homeworkProblem} %(15)
Indicate whether the following statements are TRUE or FALSE.  Motivate your answers clearly.

\begin{enumerate}[(a)]
\item If the vectors $\vec{x}_1, \vec{x}_2,\ldots,\vec{x}_m$ in $\mathbb{R}^n$ span a subspace $S$ in $\mathbb{R}^n$, the dimension of $S$ is $m$.
\item If for the $m\times n$ matrix $A$, the equation $A\vec{x} = \vec{b}$ always has at least one solution for every choice of $\vec{b}$, then the only solution to $A^T\vec{y} = \vec{0}$ is $\vec{y} = \vec{0}$.
\item If the $m$ vectors $\vec{x}_i, i=1,\ldots,m$ are orthogonal, they are also independent.  Note here that $\vec{x}_i \in \mathbb{R}^n$ and $n>m$.
\end{enumerate}


\problemAnswer{
\begin{enumerate}[(a)]


\item
%%%%% 2a      %%%%%%%%%
FALSE.  


Take for example $ \vec{x}_1 = \left ( \begin{array}{c} 1 \\ 0  \end{array} \right )$ and $ \vec{x}_2 = \left ( \begin{array}{c} 2 \\ 0  \end{array} \right )$. Then $m = 2$ but the span of $\{ \vec{x}_1,  \vec{x}_2 \} $ only has dimension  $1$.




\item
%%%%% 2b      %%%%%%%%%
TRUE.

Since $A\vec{x} = \vec{b}$ has a solution for any $\vec{b}$ , $rank(A) = m$. Then we know that  $rank(A) + nullity(A^T) = m$ or $nullity(A^T) = 0$ which implies the only solution of $A^T \vec{y} = \vec{0}$ is $\vec{y} = \vec{0}$

\item
%%%%% 2c      %%%%%%%%%
TRUE.

If $c_1, \ldots, c_m$ are scalars satisfying $c_1\vec{x}_1  + \ldots + c_m\vec{x}_m = \vec{0}$, then we may write
$$(c_1\vec{x}_1  + \ldots + c_m\vec{x}_m)^T\vec{x}_i = \vec{0}^T\vec{x}_i = \vec{0},$$ or, equivalently, 
$$ c_1(\vec{x}_1^T\vec{x}_i ) + \ldots + c_i(\vec{x}_i^T\vec{x}_i ) + \ldots + c_m(\vec{x}_m^T\vec{x}_i )= \vec{0}.$$

Since the vectors $\{\vec{x}_1, \vec{x}_2, \ldots, \vec{x}_m\}$ are orthogonal, all the inner products in the previous line vanish  with the exception of $c_i(\vec{x}_i^T\vec{x}_i)$. Thus, we have $$ c_i(\vec{x}_i^T\vec{x}_i) = \vec{0}$$  Now, since $\vec{x}_i^T\vec{x}_i \neq 0$ (we implicitly know that the $\vec{x}_i$ are nonzero for the conclusion to hold),  we must have $c_i = 0$.  Since this argument holds for all $i=1,\ldots,m$, we deduce that the set of vectors $\{\vec{x}_1, \vec{x}_2, \ldots, \vec{x}_m\}$ is linearly independent.

\end{enumerate}

}
\end{homeworkProblem}



% Problem 3



\begin{homeworkProblem} %(15)
\begin{enumerate}[(a)]
\item \begin{enumerate}[(i)]
\item Using Gram-Schmidt orthogonalization, create an orthonormal basis for $\R^2$ from the vectors
\[\vec{a}_1 = \begin{bmatrix} 3 \\ -4 \end{bmatrix}, \ \tand \vec{a}_2 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}.\]

\item Find the $QR$ decomposition of the matrix
\[ A = \begin{bmatrix} 3 & 1 & 1 \\ -4 & 1 & -1 \end{bmatrix},\]
where $Q$ is a $2 \x 2$ matrix and $R$ is $2 \x 3$.
\end{enumerate}

\item The system $A\vec{x} = \vec{b}$, with $A = \begin{bmatrix} 2 & 1 \\ 1 & 2 \end{bmatrix}, \vec{b} = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$ has the solution $\vec{x} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$. The vector $\vec{b}$ is now perturbed. The new vector is equal to $\vec{b} + \delta \vec{b}$ with $\delta \vec{b} = \begin{bmatrix} 0.001 \\ 0 \end{bmatrix}$. Estimate the maximum perturbation we can expect in th solution $\vec{x}$, measured in the vector 2-norm. For matrix-norms, you may use the Frobenius norm. 
\end{enumerate}
\problemAnswer{

\begin{enumerate}[(a)]


\item
%%%%% 3a      %%%%%%%%%
\begin{enumerate}[(i)]
\item $\vec{q}_1 = \frac{\vec{a}_1}{\|\vec{a}_1\|_2} = \frac{1}{\sqrt{3^2 + (-4)^2}}\begin{bmatrix} 3 \\ -4 \end{bmatrix} = \begin{bmatrix} 3/5 \\ -4/5 \end{bmatrix}.$ \\
$\vec{w}_2 = a_2 - (\vec{q}_1^T\vec{a}_2)\vec{q}_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \left(\begin{bmatrix} 3/5 & -4/5 \end{bmatrix}\begin{bmatrix} 1 \\ 1 \end{bmatrix} \right) \begin{bmatrix} 3/5 \\ -4/5 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \begin{bmatrix} -3/25 \\ 4/25 \end{bmatrix} = \begin{bmatrix} 28/25 \\ 21/25 \end{bmatrix}$ \\
Consider $\|\vec{w}_2\|_2 = \sqrt{\left(\frac{28}{25}\right)^2 + \left(\frac{21}{25}\right)^2} = \frac{7}{5}$. So $\vec{q}_2 = \frac{\vec{w}_2}{\|\vec{w}_2\|} = \begin{bmatrix} 4/5 \\ 3/5 \end{bmatrix}.$ \\ \\
Therefore, the orthogonal basis is $\left\{ \begin{bmatrix} 3/5 \\ -4/5 \end{bmatrix}, \begin{bmatrix} 4/5 \\ 3/5 \end{bmatrix} \right\}.$

\item The first two columns of matrix $A$ are vectors $\vec{a}_1$ and $\vec{a}_2$ from part (i). We know that $\vec{a}_1, \vec{a}_2$ form a basis of $\R^2$. So $Q = \begin{bmatrix} \vec{q}_1 & \vec{q}_2 \end{bmatrix} = \begin{bmatrix} 3/5 & 4/5 \\ -4/5 & 3/5 \end{bmatrix}$ \\ \\
We want to find $R$ such that $A = QR$. So $R = Q^TA = \begin{bmatrix} 5 & -1/5 & 7/5 \\ 0 & 7/5 & 1/5\end{bmatrix}.$

\end{enumerate}


\item
%%%%% 3b     %%%%%%%%%


\end{enumerate}
}
\end{homeworkProblem}

 
\end{document}
 
 
 
